{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knZALLJnq_2G",
        "outputId": "59e7fe22-5ad8-4f2c-9297-c1e02c1bdb82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n"
      ],
      "metadata": {
        "id": "Mv1TGtg55G5l",
        "outputId": "27c25aea-a85b-4702-9880-963b34d11ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/yolov5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd yolov5\n",
        "%pip install -qr requirements.txt "
      ],
      "metadata": {
        "id": "vh1VBKtesh8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cfca75-7211-40c3-fb61-83ba1665b467"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m595.4/595.4 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/yolov5/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgRWIJPBslpi",
        "outputId": "87aa5365-0467-4090-f09a-b5fcd35dc7ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n"
      ],
      "metadata": {
        "id": "1eJoHI22qdM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350edaac-d374-45a8-9571-cdf450ded1de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15973, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1570cc95-db17-462e-85b7-5d9751cb91f5"
      },
      "source": [
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-172-gc3c1304 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.4/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728e3015-4e5d-446f-e8ed-9d7b315bbf30"
      },
      "source": [
        "!python detect.py --weights runs/train/exp12/weights/best.pt --img 640 --conf 0.51 --source data/images --save-conf --save-txt\n",
        "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp12/weights/best.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.51, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-172-gc3c1304 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/8 /content/drive/MyDrive/yolov5/data/images/-_jpg.rf.92d5386862e64d47381cf802c8860ee4.jpg: 640x640 1 dog, 11.5ms\n",
            "image 2/8 /content/drive/MyDrive/yolov5/data/images/Screenshot 2023-06-08 at 12.07.24 AM.png: 640x576 1 dog, 41.4ms\n",
            "image 3/8 /content/drive/MyDrive/yolov5/data/images/Screenshot 2023-06-08 at 12.10.00 AM.png: 640x576 1 dog, 11.3ms\n",
            "image 4/8 /content/drive/MyDrive/yolov5/data/images/bus.jpg: 640x480 (no detections), 43.7ms\n",
            "image 5/8 /content/drive/MyDrive/yolov5/data/images/images-2.jpeg: 448x640 (no detections), 41.8ms\n",
            "image 6/8 /content/drive/MyDrive/yolov5/data/images/images-3.jpeg: 640x448 1 cat, 41.7ms\n",
            "image 7/8 /content/drive/MyDrive/yolov5/data/images/images.jpeg: 448x640 1 dog, 8.9ms\n",
            "image 8/8 /content/drive/MyDrive/yolov5/data/images/zidane.jpg: 384x640 1 dog, 44.1ms\n",
            "Speed: 0.5ms pre-process, 30.6ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp19\u001b[0m\n",
            "6 labels saved to runs/detect/exp19/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_iethsSvPRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Validate\n",
        "Validate a model's accuracy on the [COCO](https://cocodataset.org/#home) dataset's `val` or `test` splits. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH"
      },
      "source": [
        "# Validate YOLOv5s on COCO val\n",
        "!python val.py --weights yolov5.pt --data custom.yaml --img 640 --half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285fec0c-9ac8-4a4f-efda-23aefa3bbe9f"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 16 --epochs 20 --data custom.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), 3.96 KiB | 156.00 KiB/s, done.\n",
            "Command 'git fetch origin' timed out after 5 seconds\n",
            "From https://github.com/ultralytics/yolov5\n",
            "   89c3040..a199480  master     -> origin/master\n",
            "YOLOv5 ðŸš€ v7.0-172-gc3c1304 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/yolov5/dataset3/train/labels.cache... 2576 images, 84 backgrounds, 0 corrupt: 100% 2660/2660 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.2GB ram): 100% 2660/2660 [00:12<00:00, 205.59it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yolov5/dataset3/val/labels.cache... 736 images, 10 backgrounds, 0 corrupt: 100% 746/746 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.6GB ram): 100% 746/746 [00:03<00:00, 218.99it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.91 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp12/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp12\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19      3.46G    0.06918      0.025    0.02005          7        640: 100% 167/167 [00:44<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:07<00:00,  3.01it/s]\n",
            "                   all        746        738       0.74      0.662      0.774      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19      5.13G    0.04735      0.017   0.008723          7        640: 100% 167/167 [00:38<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:06<00:00,  3.51it/s]\n",
            "                   all        746        738      0.523      0.706      0.671      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19      5.13G    0.04274    0.01479   0.007735         11        640: 100% 167/167 [00:37<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:06<00:00,  3.65it/s]\n",
            "                   all        746        738      0.606      0.743      0.708      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19      5.13G    0.03831    0.01448   0.008348          8        640: 100% 167/167 [00:38<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:06<00:00,  3.57it/s]\n",
            "                   all        746        738      0.864      0.901       0.94      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/19      5.13G    0.03512     0.0139   0.007224         12        640: 100% 167/167 [00:38<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:06<00:00,  3.92it/s]\n",
            "                   all        746        738      0.846      0.861      0.907       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/19      5.13G    0.03368    0.01366   0.005967          8        640: 100% 167/167 [00:38<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.01it/s]\n",
            "                   all        746        738      0.869      0.833      0.901      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/19      5.13G    0.03113    0.01341   0.006409         10        640: 100% 167/167 [00:38<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.11it/s]\n",
            "                   all        746        738      0.917      0.892      0.938       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/19      5.13G    0.03042    0.01297   0.005507          9        640: 100% 167/167 [00:38<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.18it/s]\n",
            "                   all        746        738      0.954      0.923      0.956      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/19      5.13G     0.0288    0.01235   0.004699          8        640: 100% 167/167 [00:39<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.15it/s]\n",
            "                   all        746        738      0.948      0.949      0.975      0.715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/19      5.13G    0.02781    0.01206   0.004465          8        640: 100% 167/167 [00:39<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.22it/s]\n",
            "                   all        746        738      0.941      0.942      0.965      0.713\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/19      5.13G    0.02634    0.01185   0.004117          7        640: 100% 167/167 [00:39<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.18it/s]\n",
            "                   all        746        738      0.934      0.955       0.97      0.735\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/19      5.13G    0.02567    0.01134   0.004418          8        640: 100% 167/167 [00:39<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.20it/s]\n",
            "                   all        746        738      0.945      0.962      0.975      0.753\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/19      5.13G    0.02496      0.011   0.003442         11        640: 100% 167/167 [00:39<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.15it/s]\n",
            "                   all        746        738      0.955      0.953      0.976      0.776\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/19      5.13G    0.02386    0.01097   0.003806         10        640: 100% 167/167 [00:39<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.18it/s]\n",
            "                   all        746        738      0.949       0.96      0.972      0.768\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/19      5.13G    0.02297    0.01074   0.003838         13        640: 100% 167/167 [00:39<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.12it/s]\n",
            "                   all        746        738      0.954      0.953      0.979      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/19      5.13G    0.02189    0.01051   0.002902         10        640: 100% 167/167 [00:39<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:06<00:00,  3.90it/s]\n",
            "                   all        746        738      0.958      0.978      0.983      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/19      5.13G     0.0211    0.01008   0.002497          9        640: 100% 167/167 [00:38<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:06<00:00,  3.66it/s]\n",
            "                   all        746        738      0.964      0.978      0.982      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/19      5.13G    0.02014   0.009706   0.002084          8        640: 100% 167/167 [00:38<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:07<00:00,  3.39it/s]\n",
            "                   all        746        738      0.961      0.975       0.98      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/19      5.13G    0.01976   0.009863   0.002198         12        640: 100% 167/167 [00:38<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:07<00:00,  3.34it/s]\n",
            "                   all        746        738      0.964      0.983      0.979       0.82\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/19      5.13G    0.01906   0.009646   0.001863          9        640: 100% 167/167 [00:38<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:07<00:00,  3.42it/s]\n",
            "                   all        746        738      0.963      0.978       0.98      0.821\n",
            "\n",
            "20 epochs completed in 0.256 hours.\n",
            "Optimizer stripped from runs/train/exp12/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp12/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp12/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:10<00:00,  2.40it/s]\n",
            "                   all        746        738      0.963      0.978       0.98      0.821\n",
            "                   cat        746        251      0.962       0.98      0.981       0.85\n",
            "                   dog        746        487      0.963      0.975      0.978      0.792\n",
            "Results saved to \u001b[1mruns/train/exp12\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "# 4. Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}